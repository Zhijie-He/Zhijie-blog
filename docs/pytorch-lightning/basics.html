<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>基础教程 | Zhijie He&#39;s Blog</title>
    <meta name="generator" content="VuePress 1.9.10">
    
    <meta name="description" content="Zhijie He&#39;s learning blogs in computer science">
    
    <link rel="preload" href="/learning-blogs/assets/css/0.styles.f8b47888.css" as="style"><link rel="preload" href="/learning-blogs/assets/js/app.023149a4.js" as="script"><link rel="preload" href="/learning-blogs/assets/js/2.4cc10ed0.js" as="script"><link rel="preload" href="/learning-blogs/assets/js/1.91ea3048.js" as="script"><link rel="preload" href="/learning-blogs/assets/js/40.c9c50cde.js" as="script"><link rel="prefetch" href="/learning-blogs/assets/js/10.4d0079fb.js"><link rel="prefetch" href="/learning-blogs/assets/js/11.a25d570d.js"><link rel="prefetch" href="/learning-blogs/assets/js/12.d87c0ace.js"><link rel="prefetch" href="/learning-blogs/assets/js/13.1a43b501.js"><link rel="prefetch" href="/learning-blogs/assets/js/14.6a978a6e.js"><link rel="prefetch" href="/learning-blogs/assets/js/15.81b6c8b5.js"><link rel="prefetch" href="/learning-blogs/assets/js/16.3637d4f7.js"><link rel="prefetch" href="/learning-blogs/assets/js/17.62ca55f1.js"><link rel="prefetch" href="/learning-blogs/assets/js/18.c36d9be8.js"><link rel="prefetch" href="/learning-blogs/assets/js/19.d6620149.js"><link rel="prefetch" href="/learning-blogs/assets/js/20.a728a170.js"><link rel="prefetch" href="/learning-blogs/assets/js/21.2f0a0271.js"><link rel="prefetch" href="/learning-blogs/assets/js/22.6180816b.js"><link rel="prefetch" href="/learning-blogs/assets/js/23.878596c4.js"><link rel="prefetch" href="/learning-blogs/assets/js/24.8056bf81.js"><link rel="prefetch" href="/learning-blogs/assets/js/25.0b213a97.js"><link rel="prefetch" href="/learning-blogs/assets/js/26.5e1034dc.js"><link rel="prefetch" href="/learning-blogs/assets/js/27.91e51ec8.js"><link rel="prefetch" href="/learning-blogs/assets/js/28.065d51b5.js"><link rel="prefetch" href="/learning-blogs/assets/js/29.6e23176b.js"><link rel="prefetch" href="/learning-blogs/assets/js/3.bd89fe37.js"><link rel="prefetch" href="/learning-blogs/assets/js/30.fc97d9e8.js"><link rel="prefetch" href="/learning-blogs/assets/js/31.a4fef5bd.js"><link rel="prefetch" href="/learning-blogs/assets/js/32.304378ad.js"><link rel="prefetch" href="/learning-blogs/assets/js/33.5b418366.js"><link rel="prefetch" href="/learning-blogs/assets/js/34.8c1d4ab1.js"><link rel="prefetch" href="/learning-blogs/assets/js/35.7309b6e5.js"><link rel="prefetch" href="/learning-blogs/assets/js/36.e9ce87c9.js"><link rel="prefetch" href="/learning-blogs/assets/js/37.f17d44cc.js"><link rel="prefetch" href="/learning-blogs/assets/js/38.82558ec4.js"><link rel="prefetch" href="/learning-blogs/assets/js/39.bfee11e0.js"><link rel="prefetch" href="/learning-blogs/assets/js/4.7b60af58.js"><link rel="prefetch" href="/learning-blogs/assets/js/41.b2a2cca9.js"><link rel="prefetch" href="/learning-blogs/assets/js/42.102500cb.js"><link rel="prefetch" href="/learning-blogs/assets/js/43.be7ac4cf.js"><link rel="prefetch" href="/learning-blogs/assets/js/44.9fe9b32a.js"><link rel="prefetch" href="/learning-blogs/assets/js/45.bea8e4aa.js"><link rel="prefetch" href="/learning-blogs/assets/js/46.ec621935.js"><link rel="prefetch" href="/learning-blogs/assets/js/47.b7fae7bb.js"><link rel="prefetch" href="/learning-blogs/assets/js/48.fdc47c13.js"><link rel="prefetch" href="/learning-blogs/assets/js/49.c8489b22.js"><link rel="prefetch" href="/learning-blogs/assets/js/5.8c2caae0.js"><link rel="prefetch" href="/learning-blogs/assets/js/50.ee71df54.js"><link rel="prefetch" href="/learning-blogs/assets/js/51.c82918e2.js"><link rel="prefetch" href="/learning-blogs/assets/js/52.5370e504.js"><link rel="prefetch" href="/learning-blogs/assets/js/53.31e86553.js"><link rel="prefetch" href="/learning-blogs/assets/js/54.063a693e.js"><link rel="prefetch" href="/learning-blogs/assets/js/55.12da9be3.js"><link rel="prefetch" href="/learning-blogs/assets/js/56.ab455507.js"><link rel="prefetch" href="/learning-blogs/assets/js/6.af045fac.js"><link rel="prefetch" href="/learning-blogs/assets/js/7.f22cdc7f.js"><link rel="prefetch" href="/learning-blogs/assets/js/vendors~docsearch.11055bee.js">
    <link rel="stylesheet" href="/learning-blogs/assets/css/0.styles.f8b47888.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/learning-blogs/" class="home-link router-link-active"><!----> <span class="site-name">Zhijie He's Blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="https://github.com/Zhijie-He/learning-blogs" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="https://github.com/Zhijie-He/learning-blogs" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><a href="/learning-blogs/" class="sidebar-heading clickable router-link-active"><span>欢迎学习</span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/learning-blogs/" aria-current="page" class="sidebar-link">学前必读</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><a href="/learning-blogs/vuepress" class="sidebar-heading clickable"><span>VuePress</span> <span class="arrow right"></span></a> <!----></section></li><li><a href="/learning-blogs/markdown/" class="sidebar-link">Markdown 教程</a></li><li><section class="sidebar-group collapsable depth-0"><a href="/learning-blogs/miniprograms" class="sidebar-heading clickable"><span>微信小程序</span> <span class="arrow right"></span></a> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><a href="/learning-blogs/phd" class="sidebar-heading clickable"><span>博士</span> <span class="arrow right"></span></a> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><a href="/learning-blogs/coding-tips" class="sidebar-heading clickable"><span>编程技巧</span> <span class="arrow right"></span></a> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><a href="/learning-blogs/pytorch" class="sidebar-heading clickable"><span>PyTorch</span> <span class="arrow right"></span></a> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><a href="/learning-blogs/pytorch-timm" class="sidebar-heading clickable"><span>PyTorch Timm</span> <span class="arrow right"></span></a> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><a href="/learning-blogs/pytorch-lightning" class="sidebar-heading clickable router-link-active open"><span>PyTorch Lightning</span> <span class="arrow down"></span></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/learning-blogs/pytorch-lightning/" aria-current="page" class="sidebar-link">PyTorch Lightning 安装</a></li><li><a href="/learning-blogs/pytorch-lightning/basics.html" aria-current="page" class="active sidebar-link">基础教程</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/learning-blogs/pytorch-lightning/basics.html#训练模型" class="sidebar-link">训练模型</a></li><li class="sidebar-sub-header"><a href="/learning-blogs/pytorch-lightning/basics.html#验证和测试循环" class="sidebar-link">验证和测试循环</a></li><li class="sidebar-sub-header"><a href="/learning-blogs/pytorch-lightning/basics.html#保存和加载模型" class="sidebar-link">保存和加载模型</a></li><li class="sidebar-sub-header"><a href="/learning-blogs/pytorch-lightning/basics.html#early-stopping" class="sidebar-link">Early Stopping</a></li><li class="sidebar-sub-header"><a href="/learning-blogs/pytorch-lightning/basics.html#迁移学习" class="sidebar-link">迁移学习</a></li><li class="sidebar-sub-header"><a href="/learning-blogs/pytorch-lightning/basics.html#设置超参数" class="sidebar-link">设置超参数</a></li><li class="sidebar-sub-header"><a href="/learning-blogs/pytorch-lightning/basics.html#debug-model" class="sidebar-link">Debug model</a></li><li class="sidebar-sub-header"><a href="/learning-blogs/pytorch-lightning/basics.html#可视化metrics" class="sidebar-link">可视化metrics</a></li><li class="sidebar-sub-header"><a href="/learning-blogs/pytorch-lightning/basics.html#load-model-and-predict" class="sidebar-link">Load model and predict</a></li></ul></li><li><a href="/learning-blogs/pytorch-lightning/intermediate.html" class="sidebar-link">进阶教程</a></li><li><a href="/learning-blogs/pytorch-lightning/applications.html" class="sidebar-link">应用</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><a href="/learning-blogs/UvA-DL-notebooks" class="sidebar-heading clickable"><span>深度学习教程</span> <span class="arrow right"></span></a> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="基础教程"><a href="#基础教程" class="header-anchor">#</a> 基础教程</h1> <p><a href="https://lightning.ai/docs/pytorch/stable/levels/core_skills.html" target="_blank" rel="noopener noreferrer">https://lightning.ai/docs/pytorch/stable/levels/core_skills.html<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h2 id="训练模型"><a href="#训练模型" class="header-anchor">#</a> 训练模型</h2> <h3 id="import需要的库"><a href="#import需要的库" class="header-anchor">#</a> import需要的库</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> os
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> MNIST
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">import</span> lightning <span class="token keyword">as</span> L
</code></pre></div><h3 id="定义pytorch模型"><a href="#定义pytorch模型" class="header-anchor">#</a> 定义PyTorch模型</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Encoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>l1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">28</span> <span class="token operator">*</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>l1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">Decoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>l1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">28</span> <span class="token operator">*</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>l1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
</code></pre></div><h3 id="定义lightningmodule"><a href="#定义lightningmodule" class="header-anchor">#</a> 定义LightningModule</h3> <p>这里LightningModule负责了训练模型的全部过程，定义了<code>nn.Module</code>将如何交互：</p> <ul><li><code>training_step</code>方法定义了<code>nn.Module</code>如何交互</li> <li><code>configure_optimizers</code>方法定义了模型的optimizer</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">LitAutoEncoder</span><span class="token punctuation">(</span>L<span class="token punctuation">.</span>LightningModule<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> encoder<span class="token punctuation">,</span> decoder<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> encoder
        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> decoder

    <span class="token keyword">def</span> <span class="token function">training_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch<span class="token punctuation">,</span> batch_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># training_step defines the train loop.</span>
        x<span class="token punctuation">,</span> y <span class="token operator">=</span> batch
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        z <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x_hat <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>z<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>x_hat<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> loss

    <span class="token keyword">def</span> <span class="token function">configure_optimizers</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>self<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-3</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> optimizer
</code></pre></div><h3 id="定义训练数据集"><a href="#定义训练数据集" class="header-anchor">#</a> 定义训练数据集</h3> <p>这里和<a href="/pytorch">PyTorch</a>中一样，使用<code>DataLoader</code>去存储训练数据集：</p> <div class="language-python extra-class"><pre class="language-python"><code>dataset <span class="token operator">=</span> MNIST<span class="token punctuation">(</span>os<span class="token punctuation">.</span>getcwd<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>
</code></pre></div><h3 id="训练模型-2"><a href="#训练模型-2" class="header-anchor">#</a> 训练模型</h3> <p>这里使用Lightning中的<a href="https://lightning.ai/docs/pytorch/stable/common/trainer.html" target="_blank" rel="noopener noreferrer">Trainer<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>去负责模型的训练：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># model</span>
autoencoder <span class="token operator">=</span> LitAutoEncoder<span class="token punctuation">(</span>Encoder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Decoder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># train model</span>
trainer <span class="token operator">=</span> L<span class="token punctuation">.</span>Trainer<span class="token punctuation">(</span><span class="token punctuation">)</span>
trainer<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>model<span class="token operator">=</span>autoencoder<span class="token punctuation">,</span> train_dataloaders<span class="token operator">=</span>train_loader<span class="token punctuation">)</span>
</code></pre></div><p>实际上，这里Trainer代替我们执行下面的代码：</p> <div class="language-python extra-class"><pre class="language-python"><code>autoencoder <span class="token operator">=</span> LitAutoEncoder<span class="token punctuation">(</span>Encoder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Decoder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> autoencoder<span class="token punctuation">.</span>configure_optimizers<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> batch <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
    loss <span class="token operator">=</span> autoencoder<span class="token punctuation">.</span>training_step<span class="token punctuation">(</span>batch<span class="token punctuation">,</span> batch_idx<span class="token punctuation">)</span>

    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p>通过Trainer 我们可以极大的减少代码量。 特别是当需要验证数据集，测试数据集，分布式训练等等，Trainer可以轻易的帮助我们完成。</p> <blockquote><p>With Lightning, you can add mix all these techniques together without needing to rewrite a new loop every time.</p></blockquote> <h2 id="验证和测试循环"><a href="#验证和测试循环" class="header-anchor">#</a> 验证和测试循环</h2> <p>在上一节我们只添加了训练数据集，这一节我们将介绍如何添加验证(val)和测试(test)数据，以防模型的过拟合。</p> <h3 id="测试循环"><a href="#测试循环" class="header-anchor">#</a> 测试循环</h3> <p>首先获得测试数据集</p> <div class="language-python extra-class"><div class="highlight-lines"><br><br><br><br><br><div class="highlighted"> </div><div class="highlighted"> </div><div class="highlighted"> </div><br></div><pre class="language-python"><code>i0ort torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">as</span> data
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms

<span class="token comment"># Load data sets</span>
transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>
train_set <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&quot;MNIST&quot;</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
test_set <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&quot;MNIST&quot;</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
</code></pre></div><p>然后LightningModule里实现测试循环的方法</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">LitAutoEncoder</span><span class="token punctuation">(</span>L<span class="token punctuation">.</span>LightningModule<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">training_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch<span class="token punctuation">,</span> batch_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

    <span class="token keyword">def</span> <span class="token function">test_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch<span class="token punctuation">,</span> batch_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># this is the test loop</span>
        x<span class="token punctuation">,</span> y <span class="token operator">=</span> batch
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        z <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x_hat <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>z<span class="token punctuation">)</span>
        test_loss <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>x_hat<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token string">&quot;test_loss&quot;</span><span class="token punctuation">,</span> test_loss<span class="token punctuation">)</span>
</code></pre></div><p>一旦模型训练结束，我们即可调用<code>.test</code></p> <div class="language- extra-class"><pre class="language-text"><code>from torch.utils.data import DataLoader

# initialize the Trainer
trainer = Trainer()

# test the model
trainer.test(model, dataloaders=DataLoader(test_set))
</code></pre></div><h3 id="验证循环"><a href="#验证循环" class="header-anchor">#</a> 验证循环</h3> <p>首先获得验证数据集，惯例来说验证数据集是训练数据集的20%。不过这个量依据情况而定。</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># use 20% of training data for validation</span>
train_set_size <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_set<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.8</span><span class="token punctuation">)</span>
valid_set_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_set<span class="token punctuation">)</span> <span class="token operator">-</span> train_set_size

<span class="token comment"># split the train set into two</span>
seed <span class="token operator">=</span> torch<span class="token punctuation">.</span>Generator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">42</span><span class="token punctuation">)</span>
train_set<span class="token punctuation">,</span> valid_set <span class="token operator">=</span> data<span class="token punctuation">.</span>random_split<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span> <span class="token punctuation">[</span>train_set_size<span class="token punctuation">,</span> valid_set_size<span class="token punctuation">]</span><span class="token punctuation">,</span> generator<span class="token operator">=</span>seed<span class="token punctuation">)</span>
</code></pre></div><p>同样的在LightningModule里实现验证循环的方法</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">LitAutoEncoder</span><span class="token punctuation">(</span>L<span class="token punctuation">.</span>LightningModule<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">training_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch<span class="token punctuation">,</span> batch_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

    <span class="token keyword">def</span> <span class="token function">validation_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch<span class="token punctuation">,</span> batch_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># this is the validation loop</span>
        x<span class="token punctuation">,</span> y <span class="token operator">=</span> batch
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        z <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x_hat <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>z<span class="token punctuation">)</span>
        val_loss <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>x_hat<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">,</span> val_loss<span class="token punctuation">)</span>
</code></pre></div><p>为了调用，只需要在<code>.fit</code>函数中添加测试数据集</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_set<span class="token punctuation">)</span>
valid_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>valid_set<span class="token punctuation">)</span>
model <span class="token operator">=</span> LitAutoEncoder<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>

<span class="token comment"># train with both splits</span>
trainer <span class="token operator">=</span> L<span class="token punctuation">.</span>Trainer<span class="token punctuation">(</span><span class="token punctuation">)</span>
trainer<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> valid_loader<span class="token punctuation">)</span>
</code></pre></div><h2 id="保存和加载模型"><a href="#保存和加载模型" class="header-anchor">#</a> 保存和加载模型</h2> <h3 id="checkpoint"><a href="#checkpoint" class="header-anchor">#</a> Checkpoint</h3> <blockquote><p>It is a best practice to save the state of a model throughout the training process. This gives you a version of the model, a checkpoint, at each key point during the development of the model.</p></blockquote> <blockquote><p>Checkpoints also enable your training to resume from where it was in case the training process is interrupted.</p></blockquote> <p>Lightning Checkpoint包含了模型全部的内部状态。</p> <blockquote><p>Unlike plain PyTorch, Lightning saves everything you need to restore a model even in the most complex distributed training environments.</p></blockquote> <p>Inside a Lightning checkpoint you’ll find:</p> <ul><li>16-bit scaling factor (if using 16-bit precision training)</li> <li>Current epoch</li> <li>Global step</li> <li>LightningModule’s state_dict</li> <li>State of all optimizers</li> <li>State of all learning rate schedulers</li> <li>State of all callbacks (for stateful callbacks)</li> <li>State of datamodule (for stateful datamodules)</li> <li>The hyperparameters (init arguments) with which the model was created</li> <li>The hyperparameters (init arguments) with which the datamodule was created</li> <li>State of Loops</li></ul> <h4 id="保存checkpoint"><a href="#保存checkpoint" class="header-anchor">#</a> 保存checkpoint</h4> <p>Lightning自动在当前的工作目录中保存checkpoint, 同时保存最后epoch的state，以便可以重启训练。</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># simply by using the Trainer you get automatic checkpointing</span>
trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p>通过修改<code>default_root_dir</code>参数，修改checkpoint的存放目录</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># saves checkpoints to 'some/path/' at every epoch end</span>
trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>default_root_dir<span class="token operator">=</span><span class="token string">&quot;some/path/&quot;</span><span class="token punctuation">)</span>
</code></pre></div><h4 id="load-checkpoint"><a href="#load-checkpoint" class="header-anchor">#</a> load checkpoint</h4> <p>为了加载LightningModule以及其权重和超参：</p> <div class="language-python extra-class"><pre class="language-python"><code>model <span class="token operator">=</span> MyLightningModule<span class="token punctuation">.</span>load_from_checkpoint<span class="token punctuation">(</span><span class="token string">&quot;/path/to/checkpoint.ckpt&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># disable randomness, dropout, etc...</span>
model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># predict with the model</span>
y_hat <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
</code></pre></div><h4 id="保存超参数"><a href="#保存超参数" class="header-anchor">#</a> 保存超参数</h4> <p>通过将超参传递给init函数并且在init函数里面调用<code>self.save_hyperparameters()</code>函数，LightningModule会自动保存所有的超参数。</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">MyLightningModule</span><span class="token punctuation">(</span>LightningModule<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> learning_rate<span class="token punctuation">,</span> another_parameter<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>save_hyperparameters<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p>The hyperparameters are saved to the “hyper_parameters” key in the checkpoint</p> <div class="language-python extra-class"><pre class="language-python"><code>checkpoint <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token keyword">lambda</span> storage<span class="token punctuation">,</span> loc<span class="token punctuation">:</span> storage<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">&quot;hyper_parameters&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># {&quot;learning_rate&quot;: the_value, &quot;another_parameter&quot;: the_other_value}</span>
</code></pre></div><p>The LightningModule also has access to the Hyperparameters</p> <div class="language-python extra-class"><pre class="language-python"><code>model <span class="token operator">=</span> MyLightningModule<span class="token punctuation">.</span>load_from_checkpoint<span class="token punctuation">(</span><span class="token string">&quot;/path/to/checkpoint.ckpt&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>learning_rate<span class="token punctuation">)</span>
</code></pre></div><h4 id="load-checkpoint到nn-module"><a href="#load-checkpoint到nn-module" class="header-anchor">#</a> load checkpoint到nn.Module</h4> <blockquote><p>Lightning checkpoints are fully compatible with plain torch nn.Modules.</p></blockquote> <p>Once the autoencoder has trained, pull out the relevant weights for your torch nn.Module:</p> <div class="language-python extra-class"><pre class="language-python"><code>checkpoint <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>CKPT_PATH<span class="token punctuation">)</span>
encoder_weights <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> v <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> checkpoint<span class="token punctuation">[</span><span class="token string">&quot;state_dict&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> k<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">&quot;encoder.&quot;</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
decoder_weights <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> v <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> checkpoint<span class="token punctuation">[</span><span class="token string">&quot;state_dict&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> k<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">&quot;decoder.&quot;</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
</code></pre></div><h4 id="取消保存checkpoint"><a href="#取消保存checkpoint" class="header-anchor">#</a> 取消保存checkpoint</h4> <p>You can disable checkpointing by passing:</p> <div class="language-python extra-class"><pre class="language-python"><code>trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>enable_checkpointing<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre></div><h4 id="继续训练"><a href="#继续训练" class="header-anchor">#</a> 继续训练</h4> <p>If you don’t just want to load weights, but instead restore the full training, do the following:</p> <div class="language-python extra-class"><pre class="language-python"><code>model <span class="token operator">=</span> LitModel<span class="token punctuation">(</span><span class="token punctuation">)</span>
trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># automatically restores model, epoch, step, LR schedulers, etc...</span>
trainer<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>model<span class="token punctuation">,</span> ckpt_path<span class="token operator">=</span><span class="token string">&quot;some/path/to/my_checkpoint.ckpt&quot;</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="early-stopping"><a href="#early-stopping" class="header-anchor">#</a> Early Stopping</h2> <ul><li><a href="https://lightning.ai/docs/pytorch/stable/common/early_stopping.html" target="_blank" rel="noopener noreferrer">EarlyStopping<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <h3 id="earlystopping-callback"><a href="#earlystopping-callback" class="header-anchor">#</a> EarlyStopping Callback</h3> <p><code>EarlyStopping</code> callback可以用来作为检测一个metric的改变，当没有新的提升出现时，停止训练模型。</p> <p>为了启用<code>EarlyStopping</code>, 需要做以下步骤：</p> <ul><li>Import EarlyStopping callback.</li> <li>Log the metric you want to monitor using log() method.</li> <li>Init the callback, and set monitor to the logged metric of your choice.</li> <li>Set the mode based on the metric needs to be monitored.</li> <li>Pass the EarlyStopping callback to the Trainer callbacks flag.</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> lightning<span class="token punctuation">.</span>pytorch<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>early_stopping <span class="token keyword">import</span> EarlyStopping


<span class="token keyword">class</span> <span class="token class-name">LitModel</span><span class="token punctuation">(</span>LightningModule<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">validation_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch<span class="token punctuation">,</span> batch_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        loss <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
        self<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">,</span> loss<span class="token punctuation">)</span>


model <span class="token operator">=</span> LitModel<span class="token punctuation">(</span><span class="token punctuation">)</span>
trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>callbacks<span class="token operator">=</span><span class="token punctuation">[</span>EarlyStopping<span class="token punctuation">(</span>monitor<span class="token operator">=</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">&quot;min&quot;</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
trainer<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
</code></pre></div><p>You can customize the callbacks behaviour by changing its parameters.</p> <div class="language-python extra-class"><pre class="language-python"><code>early_stop_callback <span class="token operator">=</span> EarlyStopping<span class="token punctuation">(</span>monitor<span class="token operator">=</span><span class="token string">&quot;val_accuracy&quot;</span><span class="token punctuation">,</span> min_delta<span class="token operator">=</span><span class="token number">0.00</span><span class="token punctuation">,</span> patience<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">&quot;max&quot;</span><span class="token punctuation">)</span>
trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>callbacks<span class="token operator">=</span><span class="token punctuation">[</span>early_stop_callback<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="迁移学习"><a href="#迁移学习" class="header-anchor">#</a> 迁移学习</h2> <blockquote><p>Any model that is a PyTorch nn.Module can be used with Lightning (because LightningModules are nn.Modules also).</p></blockquote> <h3 id="使用预训练的lightningmodule"><a href="#使用预训练的lightningmodule" class="header-anchor">#</a> 使用预训练的LightningModule</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Encoder</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>


<span class="token keyword">class</span> <span class="token class-name">AutoEncoder</span><span class="token punctuation">(</span>LightningModule<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> Encoder<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> Decoder<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">CIFAR10Classifier</span><span class="token punctuation">(</span>LightningModule<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># init the pretrained LightningModule</span>
        self<span class="token punctuation">.</span>feature_extractor <span class="token operator">=</span> AutoEncoder<span class="token punctuation">.</span>load_from_checkpoint<span class="token punctuation">(</span>PATH<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>feature_extractor<span class="token punctuation">.</span>freeze<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># the autoencoder outputs a 100-dim representation and CIFAR-10 has 10 classes</span>
        self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        representations <span class="token operator">=</span> self<span class="token punctuation">.</span>feature_extractor<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>representations<span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre></div><p>We used our pretrained Autoencoder (a LightningModule) for transfer learning!</p> <h3 id="example-imagenet"><a href="#example-imagenet" class="header-anchor">#</a> Example: Imagenet</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>models <span class="token keyword">as</span> models


<span class="token keyword">class</span> <span class="token class-name">ImagenetTransferLearning</span><span class="token punctuation">(</span>LightningModule<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># init a pretrained resnet</span>
        backbone <span class="token operator">=</span> models<span class="token punctuation">.</span>resnet50<span class="token punctuation">(</span>weights<span class="token operator">=</span><span class="token string">&quot;DEFAULT&quot;</span><span class="token punctuation">)</span>
        num_filters <span class="token operator">=</span> backbone<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>in_features
        layers <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>backbone<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>feature_extractor <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>layers<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>feature_extractor<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># use the pretrained model to classify cifar-10 (10 image classes)</span>
        num_target_classes <span class="token operator">=</span> <span class="token number">10</span>
        self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_filters<span class="token punctuation">,</span> num_target_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            representations <span class="token operator">=</span> self<span class="token punctuation">.</span>feature_extractor<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>representations<span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

model <span class="token operator">=</span> ImagenetTransferLearning<span class="token punctuation">(</span><span class="token punctuation">)</span>
trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span><span class="token punctuation">)</span>
trainer<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
</code></pre></div><p>And use it to predict your data of interest</p> <div class="language-python extra-class"><pre class="language-python"><code>model <span class="token operator">=</span> ImagenetTransferLearning<span class="token punctuation">.</span>load_from_checkpoint<span class="token punctuation">(</span>PATH<span class="token punctuation">)</span>
model<span class="token punctuation">.</span>freeze<span class="token punctuation">(</span><span class="token punctuation">)</span>

x <span class="token operator">=</span> some_images_from_cifar10<span class="token punctuation">(</span><span class="token punctuation">)</span>
predictions <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
</code></pre></div><blockquote><p>We used a pretrained model on imagenet, finetuned on CIFAR-10 to predict on CIFAR-10. In the non-academic world we would finetune on a tiny dataset you have and predict on your dataset.</p></blockquote> <h2 id="设置超参数"><a href="#设置超参数" class="header-anchor">#</a> 设置超参数</h2> <h3 id="argumentparser"><a href="#argumentparser" class="header-anchor">#</a> ArgumentParser</h3> <p>ArgumentParser 是 Python 中的一项内置功能，可让您构建 CLI 程序。您可以使用它从命令行提供超参数和其他训练设置：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> argparse <span class="token keyword">import</span> ArgumentParser

parser <span class="token operator">=</span> ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Trainer arguments</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">&quot;--devices&quot;</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token comment"># Hyperparameters for the model</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">&quot;--layer_1_dim&quot;</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">)</span>

<span class="token comment"># Parse the user inputs and defaults (returns a argparse.Namespace)</span>
args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Use the parsed arguments in your program</span>
trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>devices<span class="token operator">=</span>args<span class="token punctuation">.</span>devices<span class="token punctuation">)</span>
model <span class="token operator">=</span> MyModel<span class="token punctuation">(</span>layer_1_dim<span class="token operator">=</span>args<span class="token punctuation">.</span>layer_1_dim<span class="token punctuation">)</span>
</code></pre></div><p>可以这样去调用
<code>python trainer.py --layer_1_dim 64 --devices 1</code></p> <h3 id="lightningcli"><a href="#lightningcli" class="header-anchor">#</a> LightningCLI</h3> <ul><li><a href="https://lightning.ai/docs/pytorch/stable/cli/lightning_cli_intermediate.html" target="_blank" rel="noopener noreferrer">LightningCLI<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <h2 id="debug-model"><a href="#debug-model" class="header-anchor">#</a> Debug model</h2> <blockquote><p>The Lightning Trainer has a lot of arguments devoted to maximizing your debugging productivity.</p></blockquote> <h3 id="run-all-your-model-code-once-quickly"><a href="#run-all-your-model-code-once-quickly" class="header-anchor">#</a> Run all your model code once quickly</h3> <p>if you’ve ever trained a model for days only to crash during validation or testing then this trainer argument is about to become your best friend.</p> <p>The fast_dev_run argument in the trainer runs 5 batch of training, validation, test and prediction data through your trainer to see if there are any bugs:</p> <div class="language-python extra-class"><pre class="language-python"><code>trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>fast_dev_run<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre></div><p>To change how many batches to use, change the argument to an integer. Here we run 7 batches of each:</p> <div class="language-python extra-class"><pre class="language-python"><code>trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>fast_dev_run<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span>
</code></pre></div><p>This argument will disable tuner, checkpoint callbacks, early stopping callbacks, loggers and logger callbacks like LearningRateMonitor and DeviceStatsMonitor.</p> <h3 id="shorten-the-epoch-length"><a href="#shorten-the-epoch-length" class="header-anchor">#</a> Shorten the epoch length</h3> <p>Sometimes it’s helpful to only use a fraction of your training, val, test, or predict data (or a set number of batches). For example, you can use 20% of the training set and 1% of the validation set.</p> <p>On larger datasets like Imagenet, this can help you debug or test a few things faster than waiting for a full epoch.</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># use only 10% of training data and 1% of val data</span>
trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>limit_train_batches<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> limit_val_batches<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>

<span class="token comment"># use 10 batches of train and 5 batches of val</span>
trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>limit_train_batches<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> limit_val_batches<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="print-lightningmodule-weights-summary"><a href="#print-lightningmodule-weights-summary" class="header-anchor">#</a> Print LightningModule weights summary</h3> <p>Whenever the .fit() function gets called, the Trainer will print the weights summary for the LightningModule.</p> <div class="language-shell extra-class"><pre class="language-shell"><code>  <span class="token operator">|</span> Name  <span class="token operator">|</span> Type        <span class="token operator">|</span> Params
----------------------------------
<span class="token number">0</span> <span class="token operator">|</span> net   <span class="token operator">|</span> Sequential  <span class="token operator">|</span> <span class="token number">132</span> K
<span class="token number">1</span> <span class="token operator">|</span> net.0 <span class="token operator">|</span> Linear      <span class="token operator">|</span> <span class="token number">131</span> K
<span class="token number">2</span> <span class="token operator">|</span> net.1 <span class="token operator">|</span> BatchNorm1d <span class="token operator">|</span> <span class="token number">1.0</span> K
</code></pre></div><h2 id="可视化metrics"><a href="#可视化metrics" class="header-anchor">#</a> 可视化metrics</h2> <h3 id="track-metrics"><a href="#track-metrics" class="header-anchor">#</a> Track metrics</h3> <p>Metric visualization is the most basic but powerful way of understanding how your model is doing throughout the model development process.</p> <p>To track a metric, simply use the self.log method available inside the LightningModule</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">LitModel</span><span class="token punctuation">(</span>L<span class="token punctuation">.</span>LightningModule<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">training_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch<span class="token punctuation">,</span> batch_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        value <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
        self<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token string">&quot;some_value&quot;</span><span class="token punctuation">,</span> value<span class="token punctuation">)</span>
</code></pre></div><p>To log multiple metrics at once, use self.log_dict</p> <div class="language-python extra-class"><pre class="language-python"><code>values <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;loss&quot;</span><span class="token punctuation">:</span> loss<span class="token punctuation">,</span> <span class="token string">&quot;acc&quot;</span><span class="token punctuation">:</span> acc<span class="token punctuation">,</span> <span class="token string">&quot;metric_n&quot;</span><span class="token punctuation">:</span> metric_n<span class="token punctuation">}</span>  <span class="token comment"># add more items if needed</span>
self<span class="token punctuation">.</span>log_dict<span class="token punctuation">(</span>values<span class="token punctuation">)</span>
</code></pre></div><h3 id="view-in-the-commandline"><a href="#view-in-the-commandline" class="header-anchor">#</a> View in the commandline</h3> <p>To view metrics in the commandline progress bar, set the prog_bar argument to True.</p> <div class="language-python extra-class"><pre class="language-python"><code>self<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> prog_bar<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

Epoch <span class="token number">3</span><span class="token punctuation">:</span>  <span class="token number">33</span><span class="token operator">%</span><span class="token operator">|</span>███▉        <span class="token operator">|</span> <span class="token number">307</span><span class="token operator">/</span><span class="token number">938</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">01</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">02</span><span class="token punctuation">,</span> <span class="token number">289</span><span class="token punctuation">.</span>04it<span class="token operator">/</span>s<span class="token punctuation">,</span> loss<span class="token operator">=</span><span class="token number">0.198</span><span class="token punctuation">,</span> v_num<span class="token operator">=</span><span class="token number">51</span><span class="token punctuation">,</span> acc<span class="token operator">=</span><span class="token number">0.211</span><span class="token punctuation">,</span> metric_n<span class="token operator">=</span><span class="token number">0.937</span><span class="token punctuation">]</span>
</code></pre></div><h3 id="在浏览器中展示"><a href="#在浏览器中展示" class="header-anchor">#</a> 在浏览器中展示</h3> <p>To view metrics in the browser you need to use an experiment manager with these capabilities.</p> <p>By Default, Lightning uses Tensorboard (if available) and a simple CSV logger otherwise.</p> <p>To launch the tensorboard dashboard run the following command on the commandline.</p> <div class="language-python extra-class"><pre class="language-python"><code>tensorboard <span class="token operator">-</span><span class="token operator">-</span>logdir<span class="token operator">=</span>lightning_logs<span class="token operator">/</span>
</code></pre></div><p>If you’re using a notebook environment such as colab or kaggle or jupyter, launch Tensorboard with this command</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token operator">%</span>reload_ext tensorboard
<span class="token operator">%</span>tensorboard <span class="token operator">-</span><span class="token operator">-</span>logdir<span class="token operator">=</span>lightning_logs<span class="token operator">/</span>
</code></pre></div><h2 id="load-model-and-predict"><a href="#load-model-and-predict" class="header-anchor">#</a> Load model and predict</h2> <div class="language-python extra-class"><pre class="language-python"><code>model <span class="token operator">=</span> LitModel<span class="token punctuation">.</span>load_from_checkpoint<span class="token punctuation">(</span><span class="token string">&quot;best_model.ckpt&quot;</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    y_hat <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
</code></pre></div><h3 id="使用lightningmodule"><a href="#使用lightningmodule" class="header-anchor">#</a> 使用LightningModule</h3> <p>可以在predict_step实现函数</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">MyModel</span><span class="token punctuation">(</span>LightningModule<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">predict_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch<span class="token punctuation">,</span> batch_idx<span class="token punctuation">,</span> dataloader_idx<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">(</span>batch<span class="token punctuation">)</span>

data_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> MyModel<span class="token punctuation">(</span><span class="token punctuation">)</span>
trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span><span class="token punctuation">)</span>
predictions <span class="token operator">=</span> trainer<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>model<span class="token punctuation">,</span> data_loader<span class="token punctuation">)</span>
</code></pre></div></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/learning-blogs/pytorch-lightning/" class="prev router-link-active">
        PyTorch Lightning 安装
      </a></span> <span class="next"><a href="/learning-blogs/pytorch-lightning/intermediate.html">
        进阶教程
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/learning-blogs/assets/js/app.023149a4.js" defer></script><script src="/learning-blogs/assets/js/2.4cc10ed0.js" defer></script><script src="/learning-blogs/assets/js/1.91ea3048.js" defer></script><script src="/learning-blogs/assets/js/40.c9c50cde.js" defer></script>
  </body>
</html>
