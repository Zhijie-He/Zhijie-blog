<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>应用 | Zhijie He&#39;s Blog</title>
    <meta name="generator" content="VuePress 1.9.10">
    
    <meta name="description" content="Zhijie He&#39;s learning blogs in computer science">
    
    <link rel="preload" href="/learning-blogs/assets/css/0.styles.f8b47888.css" as="style"><link rel="preload" href="/learning-blogs/assets/js/app.023149a4.js" as="script"><link rel="preload" href="/learning-blogs/assets/js/2.4cc10ed0.js" as="script"><link rel="preload" href="/learning-blogs/assets/js/1.91ea3048.js" as="script"><link rel="preload" href="/learning-blogs/assets/js/44.9fe9b32a.js" as="script"><link rel="prefetch" href="/learning-blogs/assets/js/10.4d0079fb.js"><link rel="prefetch" href="/learning-blogs/assets/js/11.a25d570d.js"><link rel="prefetch" href="/learning-blogs/assets/js/12.d87c0ace.js"><link rel="prefetch" href="/learning-blogs/assets/js/13.1a43b501.js"><link rel="prefetch" href="/learning-blogs/assets/js/14.6a978a6e.js"><link rel="prefetch" href="/learning-blogs/assets/js/15.81b6c8b5.js"><link rel="prefetch" href="/learning-blogs/assets/js/16.3637d4f7.js"><link rel="prefetch" href="/learning-blogs/assets/js/17.62ca55f1.js"><link rel="prefetch" href="/learning-blogs/assets/js/18.c36d9be8.js"><link rel="prefetch" href="/learning-blogs/assets/js/19.d6620149.js"><link rel="prefetch" href="/learning-blogs/assets/js/20.a728a170.js"><link rel="prefetch" href="/learning-blogs/assets/js/21.2f0a0271.js"><link rel="prefetch" href="/learning-blogs/assets/js/22.6180816b.js"><link rel="prefetch" href="/learning-blogs/assets/js/23.878596c4.js"><link rel="prefetch" href="/learning-blogs/assets/js/24.8056bf81.js"><link rel="prefetch" href="/learning-blogs/assets/js/25.0b213a97.js"><link rel="prefetch" href="/learning-blogs/assets/js/26.5e1034dc.js"><link rel="prefetch" href="/learning-blogs/assets/js/27.91e51ec8.js"><link rel="prefetch" href="/learning-blogs/assets/js/28.065d51b5.js"><link rel="prefetch" href="/learning-blogs/assets/js/29.6e23176b.js"><link rel="prefetch" href="/learning-blogs/assets/js/3.bd89fe37.js"><link rel="prefetch" href="/learning-blogs/assets/js/30.fc97d9e8.js"><link rel="prefetch" href="/learning-blogs/assets/js/31.a4fef5bd.js"><link rel="prefetch" href="/learning-blogs/assets/js/32.304378ad.js"><link rel="prefetch" href="/learning-blogs/assets/js/33.5b418366.js"><link rel="prefetch" href="/learning-blogs/assets/js/34.8c1d4ab1.js"><link rel="prefetch" href="/learning-blogs/assets/js/35.7309b6e5.js"><link rel="prefetch" href="/learning-blogs/assets/js/36.e9ce87c9.js"><link rel="prefetch" href="/learning-blogs/assets/js/37.f17d44cc.js"><link rel="prefetch" href="/learning-blogs/assets/js/38.82558ec4.js"><link rel="prefetch" href="/learning-blogs/assets/js/39.bfee11e0.js"><link rel="prefetch" href="/learning-blogs/assets/js/4.7b60af58.js"><link rel="prefetch" href="/learning-blogs/assets/js/40.c9c50cde.js"><link rel="prefetch" href="/learning-blogs/assets/js/41.b2a2cca9.js"><link rel="prefetch" href="/learning-blogs/assets/js/42.102500cb.js"><link rel="prefetch" href="/learning-blogs/assets/js/43.be7ac4cf.js"><link rel="prefetch" href="/learning-blogs/assets/js/45.bea8e4aa.js"><link rel="prefetch" href="/learning-blogs/assets/js/46.ec621935.js"><link rel="prefetch" href="/learning-blogs/assets/js/47.b7fae7bb.js"><link rel="prefetch" href="/learning-blogs/assets/js/48.fdc47c13.js"><link rel="prefetch" href="/learning-blogs/assets/js/49.c8489b22.js"><link rel="prefetch" href="/learning-blogs/assets/js/5.8c2caae0.js"><link rel="prefetch" href="/learning-blogs/assets/js/50.ee71df54.js"><link rel="prefetch" href="/learning-blogs/assets/js/51.c82918e2.js"><link rel="prefetch" href="/learning-blogs/assets/js/52.5370e504.js"><link rel="prefetch" href="/learning-blogs/assets/js/53.31e86553.js"><link rel="prefetch" href="/learning-blogs/assets/js/54.063a693e.js"><link rel="prefetch" href="/learning-blogs/assets/js/55.12da9be3.js"><link rel="prefetch" href="/learning-blogs/assets/js/56.ab455507.js"><link rel="prefetch" href="/learning-blogs/assets/js/6.af045fac.js"><link rel="prefetch" href="/learning-blogs/assets/js/7.f22cdc7f.js"><link rel="prefetch" href="/learning-blogs/assets/js/vendors~docsearch.11055bee.js">
    <link rel="stylesheet" href="/learning-blogs/assets/css/0.styles.f8b47888.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/learning-blogs/" class="home-link router-link-active"><!----> <span class="site-name">Zhijie He's Blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="https://github.com/Zhijie-He/learning-blogs" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="https://github.com/Zhijie-He/learning-blogs" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><a href="/learning-blogs/" class="sidebar-heading clickable router-link-active"><span>欢迎学习</span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/learning-blogs/" aria-current="page" class="sidebar-link">学前必读</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><a href="/learning-blogs/vuepress" class="sidebar-heading clickable"><span>VuePress</span> <span class="arrow right"></span></a> <!----></section></li><li><a href="/learning-blogs/markdown/" class="sidebar-link">Markdown 教程</a></li><li><section class="sidebar-group collapsable depth-0"><a href="/learning-blogs/miniprograms" class="sidebar-heading clickable"><span>微信小程序</span> <span class="arrow right"></span></a> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><a href="/learning-blogs/phd" class="sidebar-heading clickable"><span>博士</span> <span class="arrow right"></span></a> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><a href="/learning-blogs/coding-tips" class="sidebar-heading clickable"><span>编程技巧</span> <span class="arrow right"></span></a> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><a href="/learning-blogs/pytorch" class="sidebar-heading clickable router-link-active open"><span>PyTorch</span> <span class="arrow down"></span></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/learning-blogs/pytorch/" aria-current="page" class="sidebar-link">安装</a></li><li><a href="/learning-blogs/pytorch/tutorial.html" class="sidebar-link">教程</a></li><li><a href="/learning-blogs/pytorch/hyperparameter_tuning.html" class="sidebar-link">超参数优化</a></li><li><a href="/learning-blogs/pytorch/optimizer.html" class="sidebar-link">optimizer</a></li><li><a href="/learning-blogs/pytorch/transforms.html" class="sidebar-link">transforms v1 and v2</a></li><li><a href="/learning-blogs/pytorch/applications.html" aria-current="page" class="active sidebar-link">应用</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/learning-blogs/pytorch/applications.html#mnist和fashionmnist" class="sidebar-link">MNIST和FashionMNIST</a></li></ul></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><a href="/learning-blogs/pytorch-timm" class="sidebar-heading clickable"><span>PyTorch Timm</span> <span class="arrow right"></span></a> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><a href="/learning-blogs/pytorch-lightning" class="sidebar-heading clickable"><span>PyTorch Lightning</span> <span class="arrow right"></span></a> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><a href="/learning-blogs/UvA-DL-notebooks" class="sidebar-heading clickable"><span>深度学习教程</span> <span class="arrow right"></span></a> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="应用"><a href="#应用" class="header-anchor">#</a> 应用</h1> <h2 id="mnist和fashionmnist"><a href="#mnist和fashionmnist" class="header-anchor">#</a> MNIST和FashionMNIST</h2> <h3 id="准备数据集"><a href="#准备数据集" class="header-anchor">#</a> 准备数据集</h3> <p>这里以MNIST和FashionMNIST数据集为例, 这两个数据集可以通过<a href="https://pytorch.org/vision/stable/datasets.html" target="_blank" rel="noopener noreferrer">torchvision.datasets<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>下载，需要指定一些参数：</p> <blockquote><p>torchvision.datasets.MNIST(root: Union[str, Path], train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False)</p></blockquote> <ul><li>root:(str) 数据集的所在根目录</li> <li>train:(bool, optional) True读取训练数据集，False读取测试数据集</li> <li>download: (bool, optional) True则从网上下载数据集，并放在根目录中，如果数据集已经在根目录，则不会重新下载</li> <li>transform: (callable, optional) 对x进行的一些转换操作，比如将PIL图片变成tensor存储</li> <li>target_transform: (callable, optional)对x进行的一些转换操作, 比如转换成one hot存储</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torchvision
FashionMNIST_dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
MNIST_dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>FashionMNIST_dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>MNIST_dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token punctuation">(</span><span class="token operator">&lt;</span>PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span>Image image mode<span class="token operator">=</span>L size<span class="token operator">=</span>28x28 at <span class="token number">0x110D83080</span><span class="token operator">&gt;</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token operator">&lt;</span>PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span>Image image mode<span class="token operator">=</span>L size<span class="token operator">=</span>28x28 at <span class="token number">0x110D83080</span><span class="token operator">&gt;</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span>
</code></pre></div><p>可以看出在torchvision.datasets中，每一个数据是以tuple的方式进行存储，即(PIL图片, class).</p> <p>PyTorch模型训练期待的训练数据是tensor类型，所以这里针对图片需要进行转换。</p> <div class="language-python extra-class"><pre class="language-python"><code>to_tensor_transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>to_tensor_transform<span class="token punctuation">(</span>FashionMNIST_dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>to_tensor_transform<span class="token punctuation">(</span>MNIST_dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><p>在下载图片的时候，提供了transform的选项。</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms
FashionMNIST_dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
MNIST_dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>FashionMNIST_dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>FashionMNIST_dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span><span class="token keyword">class</span> <span class="token string">'torch.Tensor'</span><span class="token operator">&gt;</span>
</code></pre></div><h4 id="对数据集进行归一化处理"><a href="#对数据集进行归一化处理" class="header-anchor">#</a> 对数据集进行归一化处理</h4> <p>目前PIL图片通过ToTensor()函数进行处理，这里ToTensor不仅将数据从PIL图片格式变为tensor存储，同时将图片的值从 [0, 255] 范围自动缩放到 [0.0, 1.0] 的浮点数范围。</p> <blockquote><p>Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) or if the numpy.ndarray has dtype = np.uint8</p></blockquote> <p>然而，虽然 ToTensor() 转换确实将数据归一化到了 [0, 1]，这个区间的数据通常仍不是最理想的输入形式。大多数现代神经网络期望输入数据是以 0 为中心（zero-centered）的，这意味着数据的平均值应当接近 0。这种进一步的标准化通常有助于网络更有效地学习（特别是深层网络），因为它有助于保持激活函数输出的非线性。</p> <p>为什么需要进一步归一化？</p> <p>归一化变换会改变数据的平均值和标准差，目标是使数据集的平均值接近 0 且标准差接近 1。</p> <ul><li>零中心化（Zero-centering）：
尽管 ToTensor() 将数据缩放到了 [0, 1]，但这不意味着数据的平均值是 0.5。因此，通过减去均值，可以进一步将数据的均值移到接近 0 的位置，这通常称为零中心化。
对数据进行零中心化有助于神经网络权重的更新更加稳定，因为它确保了网络各层激活函数输入的分布更加对称和均匀。</li> <li>归一化方差（Unit Variance）：
除以标准差是为了将数据的方差归一化到 1。这有助于保持网络训练过程中的数值稳定性，避免某些层输出过大或过小，从而导致梯度消失或梯度爆炸。
让所有输入特征的标准差保持一致，有助于优化算法更有效地收敛。</li></ul> <p>参数的选择</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token triple-quoted-string string">&quot;&quot;&quot;Normalize a tensor image with mean and standard deviation.
This transform does not support PIL Image.
Given mean: ``(mean[1],...,mean[n])`` and std: ``(std[1],..,std[n])`` for ``n``
channels, this transform will normalize each channel of the input
``torch.*Tensor`` i.e.,
``output[channel] = (input[channel] - mean[channel]) / std[channel]``

.. note::
    This transform acts out of place, i.e., it does not mutate the input tensor.

Args:
    mean (sequence): Sequence of means for each channel.
    std (sequence): Sequence of standard deviations for each channel.
    inplace(bool,optional): Bool to make this operation in-place.

&quot;&quot;&quot;</span>
</code></pre></div><p>在 transforms.Normalize() 中使用的参数 (mean, std) 是特定于数据集的。这些参数用于将数据的每个通道规范化到零均值和单位方差：</p> <ul><li><p>mean：用于从每个通道中减去的均值。</p></li> <li><p>std：每个通道分别除以的标准差。
对于 MNIST 和 FashionMNIST 数据集：</p></li> <li><p>MNIST 数据集中，像素值的全局平均约为 0.1307，标准差约为 0.3081。</p></li> <li><p>FashionMNIST 数据集常用的归一化参数为 0.5，0.5，</p></li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># Choose the dataset based on the dataset_type parameter</span>
FashionMNIST_dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>
    root<span class="token operator">=</span><span class="token string">&quot;data&quot;</span><span class="token punctuation">,</span>
    train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>
        <span class="token punctuation">[</span>
            transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># FashionMNIST 数据集的均值和标准差</span>
        <span class="token punctuation">]</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

MNIST_dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>
    root<span class="token operator">=</span><span class="token string">&quot;data&quot;</span><span class="token punctuation">,</span>
    train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>
        <span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.1307</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.3081</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre></div><p>这里的MNIST和FashionMNIST只有一个通道。 注意要使用仅从训练数据集计算得出的归一化参数（即均值和标准差）。这种做法确保了测试数据在模型评估阶段的处理方式与训练数据保持一致，同时防止了潜在的数据泄露问题。</p> <p>验证结果</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 定义 DataLoader</span>
loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>MNIST_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">calculate_mean_std</span><span class="token punctuation">(</span>loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
    mean <span class="token operator">=</span> <span class="token number">0.0</span>
    std <span class="token operator">=</span> <span class="token number">0.0</span>
    total_images_count <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token keyword">for</span> images<span class="token punctuation">,</span> _ <span class="token keyword">in</span> loader<span class="token punctuation">:</span>
        batch_samples <span class="token operator">=</span> images<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        images <span class="token operator">=</span> images<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_samples<span class="token punctuation">,</span> images<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        mean <span class="token operator">+=</span> images<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        std <span class="token operator">+=</span> images<span class="token punctuation">.</span>std<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        total_images_count <span class="token operator">+=</span> batch_samples

    mean <span class="token operator">/=</span> total_images_count
    std <span class="token operator">/=</span> total_images_count

    <span class="token keyword">return</span> mean<span class="token punctuation">,</span> std

<span class="token comment"># 计算归一化后数据的平均值和标准差</span>
mean<span class="token punctuation">,</span> std <span class="token operator">=</span> calculate_mean_std<span class="token punctuation">(</span>loader<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Normalized data mean: </span><span class="token interpolation"><span class="token punctuation">{</span>mean<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Normalized data std: </span><span class="token interpolation"><span class="token punctuation">{</span>std<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>

Normalized data mean<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0001</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Normalized data std<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.9786</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><p>可以看到，这样的归一化处理结果是符合预期的。</p> <h4 id="使用dataloader"><a href="#使用dataloader" class="header-anchor">#</a> 使用DataLoader</h4> <p>使用DataLoader我们可以分批(batch)进行训练而不是一个一个样本的去训练，这样可以提高时间，还有助于改善模型的性能。</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

<span class="token keyword">def</span> <span class="token function">get_data_loader</span><span class="token punctuation">(</span>dataset_root_dir<span class="token punctuation">,</span> val_percent<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> dataset_name<span class="token operator">=</span><span class="token string">'MNIST'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment"># Choose the dataset based on the dataset_type parameter</span>
    <span class="token keyword">if</span> dataset_name <span class="token operator">==</span> <span class="token string">'FashionMNIST'</span><span class="token punctuation">:</span>
        Dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>FashionMNIST
        transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
            transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># FashionMNIST 数据集的均值和标准差</span>
        <span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        Dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST
        transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
            transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.1307</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.3081</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">]</span><span class="token punctuation">)</span>

    train_dataset <span class="token operator">=</span> Dataset<span class="token punctuation">(</span>
        root<span class="token operator">=</span>dataset_root_dir<span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
    test_dataset <span class="token operator">=</span> Dataset<span class="token punctuation">(</span>
        root<span class="token operator">=</span>dataset_root_dir<span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>  download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>

    <span class="token comment"># Percentage of validation data</span>
    N_val_samples <span class="token operator">=</span> <span class="token builtin">round</span><span class="token punctuation">(</span>val_percent <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># Split into two subsets</span>
    train_set<span class="token punctuation">,</span> val_set <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>random_split<span class="token punctuation">(</span>
        train_dataset<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_dataset<span class="token punctuation">)</span> <span class="token operator">-</span> N_val_samples<span class="token punctuation">,</span> N_val_samples<span class="token punctuation">]</span><span class="token punctuation">)</span>

    train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>
        train_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
    val_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>val_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
    test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>
        test_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> train_loader<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span> test_loader
</code></pre></div><p>这里使用<code>torch.utils.data.DataLoader</code>创建loader, 一些参数进行设置：</p> <ul><li><em>dataset</em>: 这是一个数据集对象，需要是一个实现了 <strong>getitem</strong> 和 <strong>len</strong> 方法的可迭代对象，通常是 PyTorch 的 Dataset 类的子类。这个参数指定了 DataLoader 从哪个数据集中加载数据。</li> <li><em>batch_size</em>: 默认1, 每一批多少个样本, 这直接影响到模型每次接收并处理数据的数量。较大的 batch_size 可以提高内存利用率和处理速度，但也可能影响模型训练的收敛行为和最终性能。</li> <li><em>shuffle</em>: 是否在每个训练周期（epoch）开始时随机打乱数据, 这有助于模型泛化，防止模型过拟合到数据加载顺序的特定模式。</li> <li><em>num_workers</em>:  指定有多少个子线程用于数据加载。更多的 num_workers 可以加速数据加载过程，特别是在处理大规模数据集和进行复杂转换时。0表示使用主线程进行加载数据操作</li> <li><em>drop_last</em>: 当数据集中的样本总数不能被 batch_size 整除时，是否丢弃最后一个不完整的批次。这在某些情况下很有用，特别是在使用批标准化（Batch Normalization）时，因为小批量可能会导致统计估计不准确。</li> <li><em>pin_memory</em>: 当设置为 True 时，pin_memory 参数会在将数据传递给 GPU 之前，先将数据加载到 CPU 的固定（锁页）内存中。这通常可以减少将数据从 CPU 转移到 GPU 时的时间，因为锁页内存的数据复制到 GPU 的速度更快。 适用场景：在使用 CUDA 加速的深度学习训练中，设置 pin_memory=True 可以提高数据传输效率，加快训练过程。但如果不使用 GPU，这个选项则没有影响。</li></ul> <h3 id="创建lenet5模型"><a href="#创建lenet5模型" class="header-anchor">#</a> 创建LeNet5模型</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn

<span class="token keyword">class</span> <span class="token class-name">LetNet5</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>

  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token builtin">super</span><span class="token punctuation">(</span>LetNet5<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">## MNIST images are 28x28 but LeNet5 expects 32x32</span>
    <span class="token comment">## -&gt; we pad the images with zeroes</span>
    self<span class="token punctuation">.</span>padding <span class="token operator">=</span> nn<span class="token punctuation">.</span>ZeroPad2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
    <span class="token comment">## First convolution</span>
    self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span> <span class="token number">6</span> <span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span>
    <span class="token comment">## Second convolution</span>
    self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>
    <span class="token comment">## Pooling (subsampling) layer</span>
    self<span class="token punctuation">.</span>maxpool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
    <span class="token comment">## Activation layer</span>
    self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">## Fully connected layers</span>
    self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features <span class="token operator">=</span> <span class="token number">400</span><span class="token punctuation">,</span> out_features <span class="token operator">=</span> <span class="token number">120</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>output <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
    <span class="token comment">## Final activation layer</span>
    self<span class="token punctuation">.</span>softmax <span class="token operator">=</span> nn<span class="token punctuation">.</span>LogSoftmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

  <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">## Pad the input</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>padding<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">## First convolution + activation</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">## First pooling</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">## Second Convolution + activation</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">## Second Pooling</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">## &quot;Flatten&quot; the output to make it 1D</span>
    x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token operator">*</span><span class="token number">5</span><span class="token operator">*</span><span class="token number">5</span><span class="token punctuation">)</span>
    <span class="token comment">## First full connection</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">## Second full connection</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">## Output layer</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>output<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    y <span class="token operator">=</span> self<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> y
</code></pre></div><h3 id="训练模型"><a href="#训练模型" class="header-anchor">#</a> 训练模型</h3> <p>设置一些模型必须的参数，比如损失函数，优化器</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># Create an instance of our network and move it to device</span>
model <span class="token operator">=</span> LetNet5<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

<span class="token comment"># Negative log likelihood loss</span>
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>NLLLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Stochastic Gradient Descent</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>hparams<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> momentum<span class="token operator">=</span>hparams<span class="token punctuation">.</span>momentum<span class="token punctuation">)</span>
</code></pre></div><p>在这里将训练，验证，测试写在同一个函数里面</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">run_epoch</span><span class="token punctuation">(</span>loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">:</span>
        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    running_loss<span class="token punctuation">,</span> running_accuracy <span class="token operator">=</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span>
    total_samples <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>

    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>tqdm<span class="token punctuation">(</span>loader<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f&quot;</span><span class="token interpolation"><span class="token punctuation">{</span>mode<span class="token punctuation">.</span>capitalize<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> Epoch&quot;</span></span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        x<span class="token punctuation">,</span> labels <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

        <span class="token comment"># Forward pass</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>set_grad_enabled<span class="token punctuation">(</span>mode <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>

        <span class="token comment"># Backward and optimize</span>
        <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">:</span>
            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># Calculate statistics</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            predictions <span class="token operator">=</span> outputs<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
            running_accuracy <span class="token operator">+=</span> <span class="token punctuation">(</span>predictions <span class="token operator">==</span>
                                 labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

    average_loss <span class="token operator">=</span> running_loss <span class="token operator">/</span> total_samples
    accuracy <span class="token operator">=</span> running_accuracy <span class="token operator">/</span> total_samples

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;</span><span class="token interpolation"><span class="token punctuation">{</span>mode<span class="token punctuation">.</span>capitalize<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>average_loss<span class="token punctuation">}</span></span><span class="token string">, Accuracy: </span><span class="token interpolation"><span class="token punctuation">{</span>accuracy<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> average_loss<span class="token punctuation">,</span> accuracy
</code></pre></div><p>开始训练</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>hparams<span class="token punctuation">.</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Epoch </span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">\n-------------------------------&quot;</span></span><span class="token punctuation">)</span>
    train_loss<span class="token punctuation">,</span> train_acc <span class="token operator">=</span> run_epoch<span class="token punctuation">(</span>
        train_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span>
    val_loss<span class="token punctuation">,</span> val_acc <span class="token operator">=</span> run_epoch<span class="token punctuation">(</span>
        val_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'eval'</span><span class="token punctuation">)</span>
</code></pre></div><p>这里因为MNIST和FashionMNIST的数据格式是一致的,所以可以直接训练,完整代码。</p></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/learning-blogs/pytorch/transforms.html" class="prev">
        transforms v1 and v2
      </a></span> <span class="next"><a href="/learning-blogs/pytorch-timm/">
        PyTorch Timm 安装
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/learning-blogs/assets/js/app.023149a4.js" defer></script><script src="/learning-blogs/assets/js/2.4cc10ed0.js" defer></script><script src="/learning-blogs/assets/js/1.91ea3048.js" defer></script><script src="/learning-blogs/assets/js/44.9fe9b32a.js" defer></script>
  </body>
</html>
